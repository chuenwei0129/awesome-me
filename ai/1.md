 变量命名

这是非常基础但是很多人浪费了很多时间的点。你可以把你想要的这个 变量/类 想要承担的任务和一些想法给到 copilot chat，然他输出你需要的命名

并且，copilot 的劳动力极度廉价，灵活应用 “给我十个，再给我十个，再给我十个”
人类想出十个合适答案的能力不如 llm，但很擅长从十个答案中选出合适的一个

代码速读，代码精读，加注释解析，寻找修改项

接收其他人项目、读开源项目等情况，找到需要读的文件，全选，然后打开 copilot chat（它会读取你选中的代码），使用内置的 /explian 命令，这个会内置一些 prompt 让输出质量更好

我常用的几句话是
“从架构设计角度，分析这段代码的设计思路，并讲解这种思路的优劣”
“分析 xxx 函数的详细逻辑，以及在整个文件中起到的作用”
“给 xxx 函数每一行加上注释，以详细解析该函数”
“我现在需要通过修改这个文件以实现 xxx 功能，如何修改？”
“我现在需要用 ts 重写这段 python 代码，详细解析这段 python 代码的设计逻辑，并分析如何在 ts 中实现”
“解析这段代码中可能有哪些风险”
“在这段代码中， run 和 test 方法有什么区别”

copilot 的劳动力极度廉价！
所以在我修一个大系统的 bug 时，我会对多个可能的文件问类似于 “我的需求是 xxx，能通过修改这个文件实现么？”，直到找到我需要修改的地方和方案。
llm 读懂代码逻辑的速度极快，可以快速给你一个 80 分的答案，你再判断是否有必要精读。然后再使用 copilot 辅助精读。

代码改写，用 xx 库实现整体逻辑

在要用 b 库改写使用 a 库实现的逻辑时，copilot 做的非常快，因为你 a 库写的逻辑就是最完美的 prompt，在实现完往往只需要通读一边确认答案即可。

这里涉及到对 context 的应用，而因为 codex 的数据库更新并不及时，可能并不了解 b 库。 
那一个常用的小技巧：
“这是 b 库这个函数的文档，帮我改写这部分用 a 库写的逻辑”
“这是 b 库的官方实例，我想用 b 实现 xx 功能，帮我实现”

这种 few shot 的 prompt 技巧，可以极大程度提高输出质量。不只是在这种场景，很多场景可以应用

我常用的技巧
“我需要一个 ts 类，他的使用方式和调用方式是：<伪代码>，帮我实现一个最基础的版本”
这个其实替代了之前 模板插件 的功能，帮你更快的搭起一个 class 的基础框架，然后自己填充细节。 （不会只有我每次都忘记一些 class 的语法还需要每次搜索文档 🐶）

全选所有类代码，然后 “我给这个类添加一个 xxx 函数，帮我参考现有代码，进行实现”
往往质量够用，甚至可以直接使用

“在这个 class 内，我想记录一个逐步产生的 xxx 数据，应该用什么结构比较符合 ts 的编程模式，帮我设计解释你的思路”

“这是我设计的 class/架构/数据结构，目的是 xxx，从优点和缺点各提五点理由，并详细解释原因”

大模型的劳动力极度廉价！
所以先让 copilot 替你思考，很多时候他给的架构非常优秀。即使给的质量比较差，一个错误的答案对你的思考也是有益的。 更何况廉价的劳动力，你可以引导他生成非常多，也可以质疑他的架构，并提出你看到的问题，多次沟通直到生成有意义的架构或者理清楚自己的思路。

ai-native 不是让 ai 设计架构，而是与 ai 多次讨论，让自己的思路更加清晰。 
有时候我们知道这个架构有点问题，但不知道怎么改，ai 会给你思路。有时候我们不知道这个架构有什么问题，ai 可以帮你找到问题。

总是，大模型的劳动力极度廉价，用他大量的思考来节约自己的思考

报错解析

这是我高强度使用的一个点，首先代码报错信息是给人类读的，但又不是人类可读的🐶，且人类很难有 llm 那样无限的上下文和知识
除了非常基础的报错信息，先复制给 copilot chat，使用内置的 /explain 命令，让他分析报错。如果是 vsc 用户，现在已经有一键操作了

再强调一遍，llm 不是银弹，他的答案有偏差，一定注意引导。并且，你问的问题一定是你能够判断基础对错的问题。

常用的几句话
“解释这个报错，并分析可能的原因和修改方式”
“我认为这不是报错的根源，根据的知识，给出三种可能的出错根源”

尝试一次，你就会发现，与其自己花时间去思考和分析报错，不让先让 llm 给你一个 80 分的答案，在大多数时间他的答案已经可以帮你解决问题了

基础脚手架、基础 poc

这也是 ai-native 的一部分，也是我最近用起来比较顺手的

“我要写一个 nodejs 库，帮我写 一个基础的 rollup 配置、tsconfig 和 package.json 的配置”
“帮我用 react 写一个基础的 xxx 组件”

前者是，很多时候没有好用的现成配置，用 llm 就很方便。后者是有一个迅速能看到的基础代码，会帮助你思考和工作

在这放一只猫猫，你可以摸摸它，不行的话我让它摸摸你。

　　       　∧,,　
　　　　ヾ ｀. ､`フ
　　　(,｀'´ヽ､､ﾂﾞ
　 (ヽｖ'　　　`''ﾞ'ﾞつ
　　,ゝ　 ⌒`ｙ'''´
　 （ (´＾ヽこつ
　　 ) )
　　(ノ
