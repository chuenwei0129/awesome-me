# 我的 AI 学习

## 我所了解的 ChatGPT

### token

### 一本正经胡说八道

### promt

## 本地搭建 Stable Diffusion 环境

搭建过程其实很简单，难点主要在下载 pip 包和模型上，受限于墙内的网络环境，原本简单的下载变得异常艰辛。还好在换用国内 pip 源之后，我终于在本地搭建成功 Stable Diffusion Web UI 环境。大体过程如下：

安装必须的软件环境，比如 cmake、python3.10 等
clone AUTOMATIC1111/stable-diffusion-webui: Stable Diffusion web UI (github.com)
修改 pip 源
反复执行 ./webui 直至安装成功
换模型可以在 Civitai 下载

Whisper 模型

ChatGPT 新知
中文语料少的副作用
使用英文要求 ChatGPT 创作哈姆雷特的故事，它会拒绝，因为它知道哈姆雷特，新故事如果背景差异过大，它就会拒绝。但如果用中文，因为语料不足，哈姆雷特对它来说也只是个人命，它就会很配合。

LlamaIndex（gpt-index）
Welcome to LlamaIndex (GPT Index)! — LlamaIndex documentation (gpt-index.readthedocs.io)

正在更名为 LlamaIndex（羊驼），可以将自己的数据和 LLM 结合，得到更适合自己的模型。基本上就是上面 “突破 token 限制” 逻辑的实现。比如，我们可以把一本书通过 LlamaIndex 喂给 ChatGPT， 得到的模型里就有了我们最近喂进去的知识，然后我们可以再用自然语言向 ChatGPT 提问，就会得到包含了新知识的答案。

感觉一扇新的大门正在打开。几乎所有说明书、客服，甚至一些高阶职位都可以（可能）被这个方案替代。据说实测结果，它对新知识的理解归纳总结能力都很强。

ChatPDF
ChatPDF – Chat with any PDF!

不知道跟上面一个项目是什么关系，感觉实现的功能很像。上传一个 PDF，然后使用自然语言的方式让 ChatGPT 帮你提炼内容。我试了一下，感觉很神奇，虽然我觉得不能替代完整读完一本书的价值，但帮我们快速归纳查找内容应该作用很大。

然则，我试用之后发现，它还是做不到“不知道就说不知道”，于是，如果我们的问题超出了书本和它原本模型的边界，它就又开始瞎编了。这仍然是很大的问题。因为用户可能默认它包含了书的全部内容，用户自己却不十分确定书的内容，于是很可能把错误的知识归纳当成正确的吸收。

突破 token 限制

使用 OpenAI 自己的 embedding API，将自己的数据（比如聊天记录中的数据）导入，生成更符合自己需要的模型。新的模型被之前的数据重塑过，就会看起来更符合新的要求。

原文在此：这确实是一个相当好的绕过tokens长度限制解决方案，我尝试将这个方案整理一下

ChatGPT API 增加了 messages 参数，支持显示定义角色，可以取代之前的 prompt，更清晰的标记每一个内容的来源，方便 API 生成更有价值的内容输出。OpenAI 称之为“Chat Markup Language（ChatML）”，格式如下：

我们发现，如果用英文提问，ChatGPT 找不到内容就会老老实实回答：不知道，目标资料里没有相关内容。如果用中文，它就会编造一个答案。不知道是语料导致的，还是 ChatGPT 里有相关的配置。


4097 tokens
GPT-3.5 的最大长度是 4097 token，根据我做 AI 的朋友讲解，汉字=2token，英文=0.5 token。也就是 GPT-3.5 的上下文最多保持 2k 汉字或 8k 英文字符 的内容。所有文本合并到一起发给 AI，AI 给出答案；我们再把新文本续上，发过去，AI 给出新的答案。直到最初的内容被挤出去，产生新的上下文。

这是什么意思呢？比如我们日常交流，都是自带上下文的，跟父母、跟同事、跟恋人说话不一样，也是因为上下文不同。我会跟游戏里的同好聊魔兽世界，但是如果跟父母说同样的话题，他们就会不知所云。这就是上下文的差异。

换言之，我们跟 ChatGPT 对话，用中文，教给它一件事情，累计 2k 字之后，他就会忘记这个要求。要避免这种情况，我们就得每隔一段时间重新教它一次；或者，以编程的方式重构 prompt，添加先决条件，以便维持特定功能。

听起来有理有据，但其实错误百出

前面说过，ChatGPT 可以在保留一定上下文的基础上，与当前用户进行有状态的交流。所以我们也可以教 ChatGPT 做一些事情，比如发出指令：“以后提到日期，都用 YYYY-MM-DD 的格式”。接下来，我们就能把 ChatGPT 当成自动格式转换器来使用。或者，我们可以让它换用不同的语气、不同的语法，改变输出的内容，契合某种风格。比如出名的胡总编模拟器、鲁迅模拟器等。

但这些并不是自我意识与学习，本质上只是 ChatGPT 根据完整上下文合成的文本，而已。有很大的限制：首先我们必须保留足够的上下文，其次我们也没有办法直接把这个状态转移到其它用户。

