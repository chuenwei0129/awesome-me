而 React 在类似的场景下是自顶向下的进行递归更新的，也就是说，React 中假如 ChildComponent 里还有十层嵌套子元素，那么所有层次都会递归的重新render（在不进行手动优化的情况下），这是性能上的灾难。（因此，React 创造了Fiber，创造了异步渲染，其实本质上是弥补被自己搞砸了的性能）。

他们能用收集依赖的这套体系吗？不能，因为他们遵从Immutable的设计思想，永远不在原对象上修改属性，那么基于 Object.defineProperty 或 Proxy 的响应式依赖收集机制就无从下手了（你永远返回一个新的对象，我哪知道你修改了旧对象的哪部分？）

同时，由于没有响应式的收集依赖，React 只能递归的把所有子组件都重新 render一遍，然后再通过 diff算法 决定要更新哪部分的视图，这个递归的过程叫做 reconciler，听起来很酷，但是性能很灾难。

<!-- 在React + Redux体系中，数据变更与视图变更之间的过程，就是经过了“精确——不精确——精确”这样的步骤。前一步是简单合并，而且是要改变数据引用的合并，后一步是diff。

任何时候对视图进行修改，都应该造成“整个视图被重新渲染”的效果。其它的方面都是在这个效果的基础上进行的优化，而非破坏这个效果 -->


16.6ms

react请求调度 ---- 用户输入输出处理事件 ----- setTimout ----- resize/scroll ---- raf ---- layout ---- paint ---- idle cb

空闲时间 ---- 执行任务 ---- 下一个任务单元是否存在 ---- 存在，执行任务单元 ---执行完毕 是否还有时间 ---- 有时间继续执行 下个循环 没时间---浏览器
                             ----不存在 ----浏览器


fiber 数据结构 父亲，儿子，兄弟


raf刷新页面的起点