<!-- # [专有钉钉前端面试指南](https://juejin.cn/post/6986436944913924103?utm_source=gold_browser_extension#heading-16) -->
<!-- no, it means I have the memory of a human being -->
<!-- 一个问题不好解决时，计算机科学家会选择在上面套一层 -->
<!-- 为什么 Java 和 JS 等语言需要 VM，不能直接操作内存堆栈空间？ -->
<!-- 因为js有个不成文的规定: 在期望字符串的地方一定会转换成字符串。s -->

# 知识图谱<!-- omit in toc -->

- [基础](#基础)
  - [进程和线程](#进程和线程)
    - [一起要从 CPU 说起](#一起要从-cpu-说起)
    - [从 CPU 到操作系统](#从-cpu-到操作系统)
    - [从单核到多核，如何充分利用多核](#从单核到多核如何充分利用多核)
    - [总结](#总结)
  - [协程](#协程)
  - [阻塞/非阻塞](#阻塞非阻塞)
  - [同步/异步](#同步异步)
  - [并发/并行](#并发并行)
  - [I/O](#io)
  - [什么是解释型语言？](#什么是解释型语言)
  - [V8 是如何执行 JavaScript 代码的？](#v8-是如何执行-javascript-代码的)
    - [`Parser` 生成抽象语法树](#parser-生成抽象语法树)
    - [解释器(Ignition)如何将 `AST` 翻译为字节码并执行？](#解释器ignition如何将-ast-翻译为字节码并执行)
    - [执行代码及优化](#执行代码及优化)
      - [內联算法](#內联算法)
      - [逃逸分析](#逃逸分析)
    - [JIT 编译](#jit-编译)
    - [那么变量提升呢?](#那么变量提升呢)
    - [总结](#总结-1)
  - [V8 引擎的垃圾回收](#v8-引擎的垃圾回收)
    - [JavaScript 的内存管理](#javascript-的内存管理)
    - [为什么需要垃圾回收](#为什么需要垃圾回收)
    - [V8 内存限制](#v8-内存限制)
    - [V8 垃圾回收算法](#v8-垃圾回收算法)
      - [新生代垃圾回收器 - Scavenge](#新生代垃圾回收器---scavenge)
      - [老生代垃圾回收 - Mark-Sweep & Mark-Compact](#老生代垃圾回收---mark-sweep--mark-compact)
        - [Mark-Sweep](#mark-sweep)
        - [Mark-Compact](#mark-compact)
        - [全停顿 Stop-The-World](#全停顿-stop-the-world)
      - [优化 Orinoco](#优化-orinoco)
        - [增量标记 - Incremental marking](#增量标记---incremental-marking)
        - [懒性清理 - Lazy sweeping](#懒性清理---lazy-sweeping)
        - [并发 - Concurrent](#并发---concurrent)
        - [并行 - Parallel](#并行---parallel)
      - [V8 当前垃圾回收机制](#v8-当前垃圾回收机制)
        - [副垃圾回收器](#副垃圾回收器)
        - [主垃圾回收器](#主垃圾回收器)
  - [JS 中的內存泄露](#js-中的內存泄露)
    - [JS 中的弱引用](#js-中的弱引用)
      - [WeakMap](#weakmap)
      - [WeakRef](#weakref)
    - [关于 JS 闭包是否真的会造成内存泄漏？](#关于-js-闭包是否真的会造成内存泄漏)
  - [`Babel` 的编译过程？](#babel-的编译过程)
  - [`JavaScript` 中的数组在内存中是如何存储的？](#javascript-中的数组在内存中是如何存储的)
    - [什么是数组](#什么是数组)
    - [JavaScript 中的数组](#javascript-中的数组)
    - [从 V8 源码上看数组的实现](#从-v8-源码上看数组的实现)
      - [快数组（Fast Elements）](#快数组fast-elements)
      - [慢数组（Dictionary Elements）](#慢数组dictionary-elements)
      - [快数组慢数组之间的转换](#快数组慢数组之间的转换)
      - [各有优劣](#各有优劣)
    - [扩展：ArrayBuffer](#扩展arraybuffer)
  - [浏览器和 `Node` 中的事件循环机制有什么区别？](#浏览器和-node-中的事件循环机制有什么区别)
    - [浏览器](#浏览器)
    - [Node](#node)
  - [`ES6 Modules` 相对于 `CommonJS` 的优势是什么？](#es6-modules-相对于-commonjs-的优势是什么)
  - [什么是沙箱？浏览器的沙箱有什么作用？](#什么是沙箱浏览器的沙箱有什么作用)
  - [发布 / 订阅模式和观察者模式的区别是什么？](#发布--订阅模式和观察者模式的区别是什么)
  - [装饰器模式一般会在什么场合使用？](#装饰器模式一般会在什么场合使用)
  - [什么是函数式编程？什么是响应式编程？什么是函数响应式编程？](#什么是函数式编程什么是响应式编程什么是函数响应式编程)
- [语法](#语法)
- [框架](#框架)
- [工程](#工程)
- [网络](#网络)
- [性能](#性能)
- [插件](#插件)
- [系统](#系统)
- [后端](#后端)

## 基础

### 进程和线程

#### 一起要从 CPU 说起

`CPU` 只知道两件事:

1. 从内存中取出指令
2. 执行指令，然后回到第一步

接下来的问题就是 `CPU` 从哪里取出指令呢？答案是来自一个被称为 `Program Counter`(简称 PC)的寄存器，也就是我们熟知的**程序计数器**，`PC` 寄存器中存放的是什么呢？这里存放的是**指令在内存中的地址**，什么指令呢？是 `CPU` 将要执行的下一条指令。可以简单的把寄存器理解为内存，只不过存取速度更快而已。

> 原来 `PC` 寄存器中的地址默认是自动加 `1` 的，这当然是有道理的，因为大部分情况下 `CPU` 都是一条接一条顺序执行，当遇到 `if`、`else` 时，这种顺序执行就被打破了，`CPU` 在执行这类指令时会根据计算结果来动态改变 `PC` 寄存器中的值，这样 `CPU` 就可以正确的跳转到需要执行的指令了。

![](Images/computer_2.png)

那么 `PC` 中的初始值是怎么被设置的呢？

在回答这个问题之前我们需要知道 `CPU` 执行的指令来自哪里？是来自内存，废话，内存中的指令是从磁盘中保存的可执行程序加载过来的，磁盘中可执行程序是编译器生成的，编译器又是从哪里生成的机器指令呢？答案就是我们定义的函数

![](Images/computer_01.png)

注意是**函数**，函数被编译后才会形成 `CPU` 执行的指令，那么很自然的，我们该如何让 `CPU` 执行一个函数呢？显然我们只需要找到**函数被编译后形成的第一条指令**就可以了，第一条指令就是函数入口。

现在你应该知道了吧，我们想要 `CPU` 执行一个函数，那么只需要把该函数对应的第一条机器指令的地址写入 `PC` 寄存器就可以了，这样我们写的函数就开始被 `CPU` 执行起来啦。

#### 从 CPU 到操作系统

我们想让 `CPU` 执行某个函数，那么只需要把函数对应的第一条机器执行装入 `PC` 寄存器就可以了，这样即使没有操作系统我们也可以让 `CPU` 执行程序，虽然可行但这是一个非常繁琐的过程，我们需：

1. 在内存中找到一块大小合适的区域装入程序
2. 找到函数入口，设置好 `PC` 寄存器让 `CPU` 开始执行程序

这两个步骤绝不是那么容易的事情，如果每次在执行程序时程序员自己手动实现上述两个过程会疯掉的，因此聪明的程序员就会想干脆直接写个程序来自动完成上面两个步骤吧。

> 机器指令需要加载到内存中执行，因此需要记录下内存的起始地址和长度；同时要找到函数的入口地址并写到 `PC` 寄存器中，想一想这是不是需要一个数据结构来记录下这些信息：

```c
struct *** {
   void* start_addr;
   int len;

   void* start_point;
};
```

这个**数据结构**总要有个名字吧，干脆就叫 **进程(Process)** 好了”。

就这样进程诞生了。

`CPU` 执行的第一个函数也起个名字，第一个要被执行的函数听起来比较重要，干脆就叫 `main` 函数吧。

完成上述两个步骤的程序也要起个名字，根据“弄不懂原则”这个“简单”的程序就叫操作系统(Operating System)好啦。

就这样操作系统诞生了，**程序员再也不用自己手动加载可执行程序了**。

现在进程和操作系统都有了，一切看上去都很完美。

#### 从单核到多核，如何充分利用多核

这时，假设我们想写一个程序并且要分利用**多核**该怎么办呢？

有的同学可能会说不是有进程吗，多开几个进程不就可以了？听上去似乎很有道理，但是主要存在这样几个问题：

1. 进程是需要占用内存空间的(从上一节能看到这一点)，如果多个进程基于同一个可执行程序，那么这些进程其内存区域中的内容几乎完全相同，这显然会造成内存的浪费

2. 计算机处理的任务可能是比较复杂的，这就涉及到了进程间通信，由于各个进程处于不同的内存地址空间，进程间通信天然需要借助操作系统，这就在增大编程难度的同时也增加了系统开销

该怎么办呢？

**从进程到线程**

让我再来仔细的想一想这个问题，所谓**进程无非就是内存中的一段区域，这段区域中保存了 `CPU` 执行的机器指令以及函数运行时的堆栈信息，要想让进程运行，就把 main 函数的第一条机器指令地址写入 PC 寄存器，这样进程就运行起来了。**

![](Images/computer_03.png)

进程的缺点在于只有一个入口函数，也就是 `main` 函数，因此进程中的机器指令只能被一个 `CPU` 执行，那么有没有办法让多个 `CPU` 来执行同一个进程中的机器指令呢？

聪明的你应该能想到，既然我们可以把 `main` 函数的第一条指令地址写入 `PC` 寄存器，那么其它函数和 `main` 函数又有什么区别呢？

答案是没什么区别，`main` 函数的特殊之处无非就在于是 `CPU` 执行的第一个函数，除此之外再无特别之处，我们可以把 `PC` 寄存器指向 `main` 函数，就可以把 `PC` 寄存器指向任何一个函数。

当我们把 `PC` 寄存器指向非 `main` 函数时，线程就诞生了。

![](Images/computer_04.png)

至此我们解放了思想，一个进程内可以有多个入口函数，也就是说属于同一个进程中的机器指令可以被多个 `CPU` 同时执行。

注意，这是一个和进程不同的概念，创建进程时我们需要在内存中找到一块合适的区域以装入进程，然后把 `CPU` 的 `PC` 寄存器指向 `main` 函数，也就是说进程中**只有一个执行流**。

但是现在不一样了，多个 `CPU` 可以在同一个屋檐下(进程占用的内存区域)同时执行属于该进程的多个入口函数，也就是说现在**一个进程内可以有多个执行流了**。

总是叫执行流好像有点太容易理解了，起个不容易懂的名字，就叫线程吧。

这就是线程的由来。

操作系统为每个进程维护了一堆信息，用来**记录进程所处的内存空间等**，这堆信息记为数据集 `A`。

同样的，操作系统也需要为线程维护一堆信息，用来**记录线程的入口函数或者栈信息**等，这堆数据记为数据集 `B`。

显然数据集 `B` 要比数据 `A` 的量要少，同时不像进程，**创建一个线程时无需去内存中找一段内存空间**，**因为线程是运行在所处进程的地址空间的，这就是为什么各种教材上提的创建线程要比创建进程快**(当然还有其它原因)。

> 值得注意的是，有了线程这个概念后，**我们只需要开启一个进程并创建多个线程就可以让所有 `CPU` 都忙起来，这就是所谓高性能、高并发的根本所在**。很简单，只需要创建出数量合适的线程就可以了。

> 另外值得注意的一点是，**由于各个线程共享进程的内存地址空间，因此线程之间的通信无需借助操作系统，这给程序员带来极大方便的同时也带来了无尽的麻烦**，多线程遇到的多数问题都出自于线程间通信简直太方便了以至于非常容易出错。出错的根源在于 `CPU` 执行指令时根本没有线程的概念，多线程编程面临的互斥与同步问题需要程序员自己解决。

> 最后需要提醒的是，不是说一定要有多核才能使用多线程，在单核的情况下一样可以创建出多个线程，原因在于线程是操作系统层面的实现，和有多少个核心是没有关系的，`CPU` 在执行机器指令时也意识不到执行的机器指令属于哪个线程。

#### 总结

<!-- **进程**的英文 `Process` 本意就是“过程”的意思，是一个抽象的概念。你可以理解为“一个做事的办法/步骤/方案“。注意，这里【进程】仅仅是描述这个方案的。至于这个方案是在脑海里，还是已经被执行了，是不重要的。

当然，大家更加熟知的进程往往指的是另外一个意思，是指“程序在操作系统中运行的实例“。所谓“实例”是指同一个程序可以同时在操作系统里实际的运行。就像是如果你的铺路程序写好了，可以铺好几条路。每一个具体的铺路工作是一个“实例”。 -->

1、程序

程序是一个按指定格式存储了一系列指令的编码序列。

打个比方的话，程序就好像一张菜谱，它原原本本精确记录了某道菜的整个制作流程。

2、操作系统

操作系统也是程序的一种。

它的作用是管理硬件，忽略厂商实现差异，给程序员提供一个统一的访问界面；管理其他程序，在用户需要时加载、运行它们。

操作系统可以从不同侧面划分成很多种类型。比如从预期响应时间可以分为实时系统和非实时系统；从是否允许多个程序同时被执行分可以分为单进程系统、多进程系统，多进程系统还可以分为非抢夺式多任务和抢夺式多任务等；从内核设计思路可以分微内核系统、宏内核系统……

总之，这里面的道道很多，不然 `CS` 专业的操作系统原理这门课也不会是那么厚的一本书、并且每年还要挂那么多人。

3、进程

我们把一个被载入内存、正在执行的程序叫做一个进程。

注意进程的关键点是“正在被执行”。比如你可以同时打开 `50` 个 `QQ`，这 50 个 `QQ` 是同一个程序（QQ.exe），但它在内存的 `50` 份拷贝是 `50` 个不同的进程。

还是用菜谱来打比方的话，“西红柿炒鸡蛋”这张菜谱是“程序”；你照着菜谱做这道菜是一个进程。这道菜每天中午神州大地都有成千上万厨师在做，他们做这道菜的每一次实践也都是一个不同的进程。

4、线程

“传统”观念下，一个程序只有一个执行点，就好像一张菜谱是一个厨师炒出来的一样。

但事实上，和一张菜谱可以让多个厨师分头执行它的不同部分一样，一个程序也完全可以包含两个以上的执行点，**从而利用多 CPU/核心以及不同硬件同时做几件事**。

比如说，完全可以在等待网络报文的同时把已有数据先排个序、建个索引什么的，不至于网络包没过来整个程序都没法动，把其他硬件晾一边。

一个程序允许多个执行点（执行现场）就叫多线程。

线程可以由操作系统直接调度，也可以由用户自己写一段代码，自己管理多个代码段的执行切换动作。后者就是所谓的“用户态多线程”——有人混淆了“有特殊硬件时某种 `OS` 的线程的具体实现”和“线程概念”本身，这是一知半解的典型表现。想想 `nobody` 权限下用户态线程库如何实现，或可帮他把搅来搅去乱成一团的糊涂认识分离开。

**换句话说，线程既可以由操作系统实现，也可以自己写程序实现。前者的好处是可以利用 `CPU` 里的多个核心（或多颗 CPU）；后者虽然无法利用多核心/多 `CPU`，但可以通过灵活的执行现场切换，更方便某些有特定需要的程序的设计。**

**线程和进程的区别在于，进程拥有自己的资源，而线程直接使用分配给进程的资源，它自己不能占有资源。**

<!-- 一个 cpu 可以对应多个进程，一个进程只能对应一个核心 cpu，引入线程，一个进程可以通过多个线程（函数）对应多核 cpu，线程编程角度可以理解为函数，cpu 并行必须多核心-->

### 协程

协程是一种比线程更加轻量级的存在。你可以把协程看成是跑在线程上的任务，一个线程上可以存在多个协程，但是在线程上同时只能执行一个协程。

比如，当前执行的是 `A` 协程，要启动 `B` 协程，那么 `A` 协程就需要将主线程的控制权交给 `B` 协程，这就体现在 `A` 协程暂停执行，`B` 协程恢复执行；同样，也可以从 `B 协程中启动 `A`协程。通常，如果从`A`协程启动`B`协程，我们就把`A`协程称为`B` 协程的父协程。

正如一个进程可以拥有多个线程一样，一个线程也可以拥有多个协程。**每一时刻，该线程只能执行其中某一个协程。最重要的是，协程不是被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行）。** 这样带来的好处就是性能得到了很大的提升，不会像线程切换那样消耗资源。

<!-- Callback 模式的异步编程模型需要实现大量的回调函数，大量的回调函数会打乱代码的正常逻辑，使得代码变得不线性、不易阅读，这就是我们所说的回调地狱问题。
Promise 能很好地解决回调地狱的问题，我们可以按照线性的思路来编写代码，这个过程是线性的，非常符合人的直觉。
但是这种方式充满了 Promise 的 then() 方法，如果处理流程比较复杂的话，那么整段代码将充斥着大量的 then，语义化不明显，代码不能很好地表示执行流程。我们想要通过线性的方式来编写异步代码，要实现这个理想，最关键的是要能实现函数暂停和恢复执行的功能。而生成器就可以实现函数暂停和恢复，我们可以在生成器中使用同步代码的逻辑来异步代码 (实现该逻辑的核心是协程)。
但是在生成器之外，我们还需要一个触发器来驱动生成器的执行。前端的最终方案就是 async/await，async 是一个可以暂停和恢复执行的函数，在 async 函数内部使用 await 来暂停 async 函数的执行，await 等待的是一个 Promise 对象，如果 Promise 的状态变成 resolve 或者 reject，那么 async 函数会恢复执行。因此，使用 async/await 可以实现以同步的方式编写异步代码这一目标。和生成器函数一样，使用了 async 声明的函数在执行时，也是一个单独的协程，我们可以使用 await 来暂停该协程，由于 await 等待的是一个 Promise 对象，我们可以 resolve 来恢复该协程。 -->

<!-- 虽然 JS 是单线程的，但实际上参与工作的线程一共有四个：

其中三个只是协助，只有 JS 引擎线程是真正执行的
JS 引擎线程：也叫 JS 内核，负责解析执行 JS 脚本程序的主线程，例如 V8 引擎
事件触发线程：属于浏览器内核线程，主要用于控制事件，例如鼠标、键盘等，当事件被触发时，就会把事件的处理函数推进事件队列，等待 JS 引擎线程执行
定时器触发线程：主要控制setInterval和setTimeout，用来计时，计时完毕后，则把定时器的处理函数推进事件队列中，等待 JS 引擎线程。
HTTP 异步请求线程：通过XMLHttpRequest连接后，通过浏览器新开的一个线程，监控readyState状态变更时，如果设置了该状态的回调函数，则将该状态的处理函数推进事件队列中，等待JS引擎线程执行。
注：浏览器对同一域名的并发连接数是有限的，通常为 6 个。 -->

### 阻塞/非阻塞

> **阻塞/非阻塞**：这是从用户/任务安排者/调度者角度看待问题。

**阻塞**：**当你开始一个任务、执行一个函数时，你必须等待这个任务完成、或者函数返回。这个等待时间可能很长，期间你不能做其他事。**

比如，`Windows` 下载了更新，要求你重启以应用更新时，这个更新就是阻塞的，在它完成前你的电脑不能做别的事。

再比如，你可以用 `select` 等待网络上传来消息；在消息传来之前，你的程序就阻塞了。什么时候消息来了，什么时候它才能继续执行。

**非阻塞**：**启动一个任务后你就可以去干别的了，不需要等待它返回结果。**

比如，你可以启动下载器下载一部电影；与之同时你可以做别的事。

再比如，你可以把 `select` 丢进一个线程，当网络上有消息传来时，这个线程会触发一个事件。此时 `select` 本身仍然是阻塞的，但你的程序主线程是非阻塞的，它完全可以支持你打字、看电影、玩游戏。

再举个例子：假设网络比较忙，你给小明发了个很大的图片。那么阻塞模式下，这个图片发完之前你什么都不能干，只能干等着；而非阻塞模式下，程序可以把图片先保存在缓冲区、等网络空闲了自动发送——而你完全可以继续敲字、继续和他聊天。这些聊天内容完全可以马上出现在小明的手机上，只是图片还需要三分钟他才能看到。

换句话说，讨论阻塞我们需要先明确观察者。对 `sendfile` 函数，它可能永远是阻塞的；但经过一定的技术处理，我们完全可以让我们的用户非阻塞的使用 `sendfile`。

### 同步/异步

> **同步/异步**：这也是从用户/任务安排者/调度者角度看问题，但它更偏向“我们会得到什么”。

**同步**：**程序/函数返回我们马上就得到执行结果。**

**异步**：**程序/函数返回我们只能拿到一张“凭据”，在一定时间后，我们可以凭这张“凭据”取得执行结果**。

比如，你到医院看病，医生望闻问切之后给你下了诊断书，这就是同步调用。

反之，你到医院看病，先去拍 `CT`，然后拿到个条码。过了两个半小时后，你拿这张条码到取影像处拿到了你的片子和医生诊断书，这就是异步调用。

**大多数时候，同步调用是阻塞的，异步调用是非阻塞的**。同步改异步也是常用的把阻塞式调用改成非阻塞调用的通用手段。

当然，你也完全可以搞一个奇葩实现，把异步调用（的某些步骤）弄成阻塞的。

换句话说，**这个概念和阻塞/非阻塞存在一定的关系，但彼此仍然是正交的**。

### 并发/并行

> 并发是完全从任务调度角度看待问题；而**并行则要求任务同时执行**。

**并发**：你可以同时安排我做 `20` 个任务；但这些任务我以什么顺序做、会不会同时做，这你管不着。

**并行**：当我做这 `20` 个任务时，发现某些任务是可以同时做的——比如，我可以在给你做饭的同时，接你老师的电话。

比如，这个学期你要学习语文数学物理化学，这就是并发。但学语文时你就不能学数学，换句话说没法并行。

特别的，如果一个系统是阻塞的，那么显然我们就不可能并发的给它安排任务。不能并发的安排任务，那么当然也就不可能并行——因为你一次只能领一个任务。

**分布式**：分布式说的是软件架构。简单说，把任务分解、放到联网的一堆电脑上执行，这就是分布式。

<!-- 并发不一定并行，并行一定是并法 -->

拓展：[怎样理解阻塞非阻塞与同步异步的区别？](https://www.zhihu.com/question/19732473)

### I/O

![](Images/computer_10.png)

<!-- 阻塞和非阻塞区别在于如果数据没准备好,是等准备好完成操作再返回, 还是立马返回一个没准备好, 而同步/异步区别在于数据的“读/写”过程，进程是否处于阻塞的状态。 -->

典型的异步 `I/O` 驱动的 `runtime` 就是浏览器，你写 `js` 的时候，比如你想当用户点击一个按钮的时候，就执行一段程序，这时可以肯定的是肯定不能用最开始的阻塞 `I/O` 模型，因为你一旦执行，你的网页在用户点击这个按钮之前，就卡死了，所以浏览器环境是采用的非阻塞异步 `I/O` 模型，不管是用户鼠标点击还是 `ajax` 请求，你的 `js` 代码无需等待，数据的传入也不需你等待，当开始执行 `handler` 的时候，数据也已经读写完毕了，这种模型对于做 `UI` 很有用。

那么把思路扩展到服务端，如果是阻塞 `I/O` 型的话，每个用户请求时都要和服务端维持一个 `TCP` 连接，那么很显然如果服务端的应用是单线程的，用阻塞 `I/O` 就没办法同时处理多个用户的连接了（其实可以，一会儿会讲到 `I/O` 多路复用）。

那么这时我们的思路就是为每个用户都准备一个独立的线程，假如同时有五十个用户向服务端发起请求，我们就创建五十个线程，每个线程处理每个用户，比如 Tomcat 就是这样的逻辑，对于一般的 HTTP 请求，这种方式的效果是不错的，因为一般 Restful 的 HTTP 请求，其特点是只要请求过来，它马上就是可读的，马上处理，这个连接马上也是可写的，直接返回相应数据就好， 数据返回之后，就可以断开连接了（一个 TCP 连接也可以进行多了 HTTP 请求）。

但是由于线程本身的创建和维持是有成本的，而且线程是可以复用的，为了达到一种最佳的效果，往往会规定一个线程数的最大上限，比如 100 个，然后我们维持一些线程，当线程的任务结束了之后，我们不销毁这个线程，而是让这个线程处理下一个用户的请求，这个就叫线程池。线程池太小了（如果是一个线程，就成单线程了）不好，线程池太大（上限是无穷，等于每进来一个请求，创建一个新线程）也不好。

但是如果你要开发一个聊天软件，比如微信，为了能保证每个用户能收到消息，用户的手机和你的服务器必须维持一个连接，比方说是 TCP 连接。这个连接一旦创建，在绝大多数时候，服务端是无法从和你的手机之间的连接中读取数据的，也就是“不可读”，也就是处于等待的过程，而为了能把别人给你发的消息推送给你，这个连接也必须保持。如果你的微信一直在后台运行，可以说你和腾讯的服务器的连接一整天都没有断过，这和你访问百度，完成一个网页的请求后马上断开连接是有很大区别的。

那么这时，用多线程，每个线程用阻塞 I/O 的方式，就显得很不值得了，因为大多数时候你的每个线程都是处于 idle 状态，也就是什么都不做，没有东西可读，也没有东西可写。假如你有十万个用户，那你就要同时维持十万个连接，每个连接一个线程就是十万个线程，最后服务器变得异常慢（切换线程的成本太高，平坦给每个线程的时间太少）。所以这时候，使用非阻塞的方式显然更好一些。

只用一个线程的话，这个线程不断地询问这十万个人，谁可读，谁可写，如果可写或可读，就执行相应的读写操作（执行的时候已经准备好了，所以读写时间也挺短，比如读一个 1KB 的数据，可能是 0.01 秒）最后很可能单线程，平均每个用户也能获得不错的消息推送效果。

有兴趣的同学可以去了解一下 linux 的 select 和 poll 两个系统调用，它们能使用 I/O 多路复用来更好地完成上面的操作。

但后来你发现你的服务器的带宽不够了，所以很多数据来不及发送出去，比如你服务器的带宽是 2MB/S, 但是你每秒要发送 3Mb/s 的数据,这样你有些数据发送不出去,就只能越积越多, 就像排队一样, 越排越多，这样给你的服务器带来了内存的压力，而且也提高了服务器宕机的损失（一旦服务器挂掉，所有还没有转发出去的消息全部丢失，收消息的人永远收不到消息了）。

所以后来，你把消息分为两类，一类是普通的小本文消息，这种消息要保证实时性，就直接转发，另一种是文件消息，比如你在微信上给别人发一条消息，服务器收到后需要转发给收信人，这种文件比较大，传输的过程也可能会遇到网络问题而造成传输失败，但是它的特点是对传输信息的时间不是很敏感，即便延迟两三秒，问题也不大，于是你打算让文件的 I/O 做异步处理，于是你的这台服务器只需要将这些文件写入一个消息队列即可，消息的等待和发送都不用再管了。消息队列很有可能安排在另一台服务器上，或者一个服务器集群上，这个集群负责每时每刻根据目前的网络状态将写入消息队列的数据发送出去，而这个队列也有持久化的能力，可以把文件存到硬盘上，不用担心宕机后数据丢失，当流量高峰的时候，队列很长，流量低峰的时候，队列往往是空的，但是这一切你原来那台服务器都不管，只需将文件写入这个消息队列中即可。

所以异步，其实就是包括 I/O 的读写，都不是调用 I/O 的人进行的，而是别人进行的，只是进行完之后，有可能会通知调用方。

### 什么是解释型语言？

语言是用来写代码的，代码是给人看的。

计算机只看得懂程序（`01010101`），看不懂代码。

把代码变成程序有两个常用的方法：

1. 把所有的代码变成程序，再执行。
   **即，先编译再执行**。
2. 把一丢丢代码变成一丢丢程序执行，然后再把一丢丢代码变成一丢丢程序执行，...。
   **即，边解释边执行**。

谁来编译？谁来解释？谁来执行？

- **编译型**：编译器来编译，系统执行。
- **解释型**：解释器解释并执行。

举个例子 🌰：

你女网友只懂中文（源代码），你只懂英文（机器码/CPU 指令），现在你俩要搞对象，怎么办？

女网友写下了自己的：`要求.py`:

```py
二号男嘉宾
我要吃好的
我要穿好的
我要住好的
我不会做饭
我不会家务
我脾气不好
```

由于你们语言不通，直接是无法交流的，所以必须要有一个翻译官（python 解释器）

1. `python` 解释器的执行流程：

```py
二号男嘉宾 => SLOT #2
我要吃好的 => FOOD +10W
我要穿好的 => DRESS + 10W
我要住好的 => HOUSE + 100W
我不会做饭 => ELEME + 7W
我不会家务 => BABYSITTER + 3W
我脾气不好 => PSYCHOLOGIST + 10W
```

翻译官将中文翻译成了你能懂的英文（CPU 指令），这是你的执行流程：

```py
SLOT #2 => ACK
FOOD +10W => +10W
DRESS + 10W => +10W
HOUSE + 100W => +100W
ELEME + 7W => +7W
BABYSITTER + 3W => +3W
PSYCHOLOGIST + 10W => +10W
```

**每接到一次指令，你就去 `ATM` 取一次钱，一共需要取 `6` 次钱；**

然后你将继续等待对方开出的条件，进入 `Idle` 状态，直到翻译将新的指令给你，直到条件开完毕，而你又能一直从 `ATM` 里面取出钱来，然后你们就幸福的在一起了。

2. `JIT` 优化。

你应该看出来了，`Python` 解释器（翻译官）每次传递一行指令，但要求其实都差不多，所以 `JIT` 这时候就派上用场了，**第一次的过程其实是一样的**，但是你的女网友发现你没有回复她的时候，又说了一遍，还说了第三遍，这个时候如果有 `JIT`（比如 `Pypy`），那么从第二次开始，翻译官给你的就不再是一行一行的指令了，而是：

```py
+10W + 10W + 100W + 7W + 3W + 10W
```

**这时候，你只需要去一次 `ATM`，一次性取出需要的这些钱，你们就能幸福的在一起了。**

3. 什么是跨平台呢？

跨平台其实就是 `CPU` 的指令集不太一样，你让懂 `ARM` 的翻译官来翻译给 `Power 7` 听，无论如何都听不懂的，比如你去 `ATM` 里面取钱这个指令翻译成不同 `CPU` 指令就是不一样的：

- `x86`：神昏证，应喊卡，本人，余额足够
- `power7`： 爹，我，钱，`140W`
- `A11`： 秦始皇，封侯，打钱
- `ARM`：果照，`30%` 利率，无敌呀饭款，`30` 秒到站

只要有对应的解释器，你总是能取到钱

4. 顺提一下编译型：

就是翻译官（此处应该叫编译官）把 **你女网友的** `要求.py` 直接重新找了一张 `A4` 纸，上面写着：

```py
$$
```

这样每次你女网友拿着这张纸到`x86`窗口的`ATM`直接就能办理了，**注意，仅此窗口，别家店不可以用的**，咦，好像少了什么人？也是，如果都能直接跟`ATM`沟通了，谁还需要男盆友呢？

5. 性能

因为解释型语言在编译的时候只是编译成了字节码，运行的时候，还需要解释器挨个把字节码翻译成机器语言才能执行。

相当于你写的程序，每次都要先“编译”，再运行，运行速度必然比只需要运行不需要编译的编译型语言慢。

`JavaScript` 是一种动态类型语言，在编译时并不能准确知道变量的类型，只可以在运行时确定，这就不像 `c++`或者 `java` 等静态类型语言，在编译时候就可以确切知道变量的类型。然而，在运行时计算和决定类型，会严重影响语言性能，这也就是 `JavaScript` 运行效率比 `C++`或者 `JAVA` 低很多的原因之一。

> 例子来源：[什么是解释型语言？](https://www.zhihu.com/question/268303059)

### V8 是如何执行 JavaScript 代码的？

`V8` 执行 `JS` 代码的整体流程如下图所示：

![](Images/v8_03.png)

在这个过程中，`V8` 同时使用了 `Parser`（解析器）、`Ignition`（解释器） 和 `TurboFan`（编译器） 来执行 `JS` 代码

#### `Parser` 生成抽象语法树

在 `Chrome` 中开始下载 `Javascript` 文件后，`Parser` 就会**开始并行在单独的线程上解析代码**。这意味着解析可以在下载完成后仅几毫秒内完成，并生成 `AST`。

> TIPS：解析过程中，对于不是立即执行的函数，只进行预解析（Pre Parser）只有当函数调用时才对函数进行全量解析。

![](Images/v8_11.png)

此外，`AST` 还广泛应用于各类项目中，比如 `Babel`、`ESLint`，那么 `AST` 的生成过程是怎么样的呢？

1. **词法分析**（lexical analysis）：主要是将字符流（`char stream`） 转换成标记流（`token stream`），字符流就是我们一行一行的代码，`token` 是指语法上不能再分的、最小的单个字符或者字符串。

![](Images/v8_12.jpg)

```js
var name = 'ivweb'[
  //转成token后为

  ({
    type: 'Keyword',
    value: 'var'
  },
  {
    type: 'Identifier',
    value: 'name'
  },
  {
    type: 'Punctuator',
    value: '='
  },
  {
    type: 'String',
    value: '"ivweb"'
  },
  {
    type: 'Punctuator',
    value: ';'
  })
]
```

从上面可以看出，`var name = "ivweb";` 这样一段代码，会有关键字 `"var"`、标识符 `"name"`、赋值运算符 `"="`、字符串 `"ivweb"`、分隔符 `";"`，共 `5` 个 `token`。

2. **语法分析**：将前面生成的 `token` 流根据语法规则，形成一个有元素层级嵌套的语法规则树，这个树就是 `AST`。在此过程中，如果源代码不符合语法规则，则会终止，并抛出“语法错误”。

#### 解释器(Ignition)如何将 `AST` 翻译为字节码并执行？

- 字节码是机器码的抽象，可以看作是小型的构建块，这些构建块组合到一起构成任何 `JavaScript` 功能。

- 字节码比机器码占用更小的内存，这也是为什么 `V8` 使用字节码的一个很重要的原因。

- 字节码不能够直接在处理器上运行，需要通过解释器将其转换为机器码后才能执行。

![](Images/v8_04.png)

举个例子 🌰：

![](Images/v8_10.png)

#### 执行代码及优化

##### 內联算法

![](Images/v8_05.png)

![](Images/v8_06.png)

![](Images/v8_07.png)

![](Images/v8_08.png)

通过內联可以降低复杂度、消除冗余代码、合并常量，內联技术通常也是逃逸分析的基础。

##### 逃逸分析

> 分析对象的生命周期是否仅限于当前函数

![](Images/v8_09.png)

逃逸分析的好处是，直接将变量加载到寄存器上，不再需要从内存中访问对象属性，还减少了内存占用。

#### JIT 编译

![](Images/v8_02.jpg)

`Ignition` 执行上一步生成的字节码，并记录代码运行的次数等信息，如果同一段代码执行了很多次，就会被标记为 `“HotSpot”`（热点代码）。

然后把这段代码发送给编译器 `TurboFan`，然后 `TurboFan` 把它编译为更高效的机器码储存起来，等到下次再执行到这段代码时，就会用现在的机器码替换原来的字节码进行执行，这样大大提升了代码的执行效率。

另外，当 `TurboFan` 判断一段代码不再为热点代码的时候，会执行去优化的过程，把优化的机器码丢掉，然后执行过程回到 `Ignition`。

#### 那么变量提升呢?

下面是 `JavaScript` 处理声明语句的过程：

1. 一旦 `V8` 引擎进入一个执行具体代码的执行上下文（函数），它就对代码进行词法分析或者分词。这意味着代码将被分割成像`foo = 10`这样的原子符号（atomic token）。

2. 在对当前的整个作用域分析完成后，引擎将 `token` 解析翻译成一个`AST`（抽象语法树）。
   引擎每次遇到声明语句，就会把声明传到作用域（scope）中创建一个绑定。每次声明都会为变量分配内存。只是分配内存，并不会修改源代码将变量声明语句提升。正如你所知道的，在`JS`中分配内存意味着将变量默认设为`undefined`。

3. 在这之后，引擎每一次遇到赋值或者取值，都会通过作用域（scope）查找绑定。如果在当前作用域中没有查找到就接着向上级作用域查找直到找到为止。

4. 接着引擎生成 `CPU` 可以执行的机器码。
   最后，代码执行完毕。

所以变量提升不过是执行上下文的小把戏。在执行任何语句之前，解释器就要从创建执行上下文后已经存在的作用域（scope）中找到变量的值。

#### 总结

那么结合上面对于 `V8` 引擎的介绍，我们在编程中应注意：

- **类型**。对于函数，`JavaScript` 是一种动态类型语言，`JavaScriptCore` 和 `V8` 都使用隐藏类和内嵌缓存来提高性能，为了保证缓存命中率，**一个函数应该使用较少的数据类型**；对于数组，应尽量存放相同类型的数据，这样就可以通过偏移位置来访问。
- **数据表示**。简单类型数据（如整型）直接保存在句柄中，可以减少寻址时间和内存占用，如果可以使用整数表示的，尽量不要用浮点类型。
- **内存**。虽然 `JavaScript` 语言会自己进行垃圾回收，但我们也应尽量做到及时回收不用的内存，对不再使用的对象设置为 `null` 或使用 `delete` 方法来删除(使用 `delete` 方法删除会触发隐藏类新建，需要更多的额外操作)。
- **优化回滚**。在执行多次之后，不要出现修改对象类型的语句，尽量不要触发优化回滚，否则会大幅度降低代码的性能。
- **新机制**。使用 `JavaScript` 引擎或者渲染引擎提供的新机制和新接口提高性能。

知识拓展：[认识 V8 引擎](https://zhuanlan.zhihu.com/p/27628685)

### V8 引擎的垃圾回收

#### JavaScript 的内存管理

不管什么程序语言，内存生命周期基本是一致的：

1. 分配你所需要的内存
2. 使用分配到的内存（读、写）
3. 不需要时将其释放归还

与其他需要手动管理内存的语言不通，在 `JavaScript` 中，当我们创建变量（对象，字符串等）的时候，系统会自动给对象分配对应的内存。

```js
const age = 28 // 给数值变量分配内存
const str = 'chu' // 给字符串分配内存

const o = {
  a: 1,
  b: null
} // 给对象及其包含的值分配内存

// 给数组及其包含的值分配内存（就像对象一样）
const a = [1, null, 'chu']

function f(a) {
  return a + 2
} // 给函数（可调用的对象）分配内存

// 函数表达式也能分配一个对象
someElement.addEventListener(
  'click',
  function () {
    someElement.style.backgroundColor = 'blue'
  },
  false
)
```

**当系统发现这些变量不再被使用的时候，会自动释放（垃圾回收）这些变量的内存，开发者不用过多的关心内存问题。**

#### 为什么需要垃圾回收

在 `JavaScript` 中，数据类型分为两类，简单类型和引用类型，对于简单类型，内存是保存在栈（stack）空间中，复杂数据类型，内存是保存在堆（heap）空间中。

- **基本类型**：这些类型在内存中分别占有固定大小的空间，他们的值保存在栈空间，我们通过按值来访问的
- **引用类型**：引用类型，值大小不固定，栈内存中存放地址指向堆内存中的对象。是按引用访问的。

> 对于栈的内存空间，只保存简单数据类型的内存，由操作系统自动分配和自动释放。而堆空间中的内存，由于大小不固定，系统无法无法进行自动释放，这个时候就需要 `JS` 引擎来手动的释放这些内存。

#### V8 内存限制

在 `Chrome `中，`v8` 被限制了内存的使用（64 位约 `1.4G/1464MB` ， 32 位约 `0.7G/732MB`），为什么要限制呢？

1. 表层原因是，`V8` 最初为浏览器而设计，不太可能遇到用大量内存的场景
2. 深层原因是，`V8` 的垃圾回收机制的限制（如果**清理大量的内存垃圾是很耗时间，这样会引起 `JavaScript` 线程暂停执行的时间**，那么性能和应用直线下降）

#### V8 垃圾回收算法

> TIPS: `64` 位新生代的空间为 `64MB`,老生代为 `1400MB` > `32` 位新生代的空间为 `32MB`,老生代为 `700MB`
> 最新版的 `node(v14)`的内存为 `2 GB`

在 `JavaScript` 中，其实绝大多数的对象存活周期都很短，大部分在经过一次的垃圾回收之后，内存就会被释放掉，而少部分的对象存活周期将会很长，一直是活跃的对象，不需要被回收。为了提高回收效率，`V8` 将堆分为两类新生代和老生代，新生代中存放的是生存时间短的对象，老生代中存放的生存时间久的对象。

##### 新生代垃圾回收器 - Scavenge

在 `JavaScript` 中，任何对象的声明分配到的内存，将会先被放置在新生代中，而因为大部分对象在内存中存活的周期很短，所以需要一个效率非常高的算法。在新生代中，主要使用 `Scavenge` 算法进行垃圾回收，`Scavenge` 算法是一个典型的**牺牲空间换取时间**的复制算法，在占用空间不大的场景上非常适用。

`Scavenge` 算法将新生代堆分为两部分，分别叫 `from-space` 和 `to-space`，工作方式也很简单，就是将 `from-space` 中存活的活动对象复制到 `to-space` 中，并将这些对象的内存有序的排列起来，然后将 `from-space` 中的非活动对象的内存进行释放，完成之后，将 `from space` 和 `to space` 进行互换，这样可以使得新生代中的这两块区域可以重复利用。

![](Images/js_memo_01.png)

简单的描述就是：

1. 标记活动对象和非活动对象
2. 复制 `from space` 的活动对象到 `to space` 并对其进行排序
3. 释放 `from space` 中的非活动对象的内存
4. 将 `from space` 和 `to space` 角色互换

那么，垃圾回收器是怎么知道哪些对象是活动对象和非活动对象的呢？

有一个概念叫对象的可达性，表示从初始的根对象（window，global）的指针开始，这个根指针对象被称为根集（root set），从这个根集向下搜索其子节点，被搜索到的子节点说明该节点的引用对象可达，并为其留下标记，然后递归这个搜索的过程，直到所有子节点都被遍历结束，那么没有被标记的对象节点，说明该对象没有被任何地方引用，可以证明这是一个需要被释放内存的对象，可以被垃圾回收器回收。

新生代中的对象什么时候变成老生代的对象呢？

在新生代中，还进一步进行了细分，分为 `nursery` 子代和 `intermediate` 子代两个区域，一个对象第一次分配内存时会被分配到新生代中的 `nursery` 子代，如果进过下一次垃圾回收这个对象还存在新生代中，这时候我们移动到 `intermediate` 子代，再经过下一次垃圾回收，如果这个对象还在新生代中，副垃圾回收器会将该对象移动到老生代中，这个移动的过程被称为晋升。

##### 老生代垃圾回收 - Mark-Sweep & Mark-Compact

新生代空间中的对象满足一定条件后，晋升到老生代空间中，在老生代空间中的对象都已经至少经历过一次或者多次的回收所以它们的存活概率会更大，如果这个时候再使用 `scavenge` 算法的话，会出现两个问题：

- `scavenge` 为复制算法，重复复制活动对象会使得效率低下
- `scavenge` 是牺牲空间来换取时间效率的算法，而老生代支持的容量交大，会出现空间资源浪费问题

所以在老生代空间中采用了 `Mark-Sweep`（标记清除） 和 `Mark-Compact`（标记整理） 算法。

###### Mark-Sweep

`Mark-Sweep` 处理时分为两阶段，标记阶段和清理阶段，看起来与 `Scavenge` 类似，不同的是，`Scavenge` 算法是复制活动对象，而由于在老生代中活动对象占大多数，所以 `Mark-Sweep` 在标记了活动对象和非活动对象之后，直接把非活动对象清除。

- 标记阶段：对老生代进行第一次扫描，标记活动对象
- 清理阶段：对老生代进行第二次扫描，清除未被标记的对象，即清理非活动对象

![](Images/js_memo_10.gif)

看似一切 `perfect`，但是还遗留一个问题，被清除的对象遍布于各内存地址，产生很多内存碎片。

![](Images/js_memo_02.png)

###### Mark-Compact

由于 `Mark-Sweep` 完成之后，老生代的内存中产生了很多内存碎片，若不清理这些内存碎片，如果出现需要分配一个大对象的时候，这时所有的碎片空间都完全无法完成分配，就会提前触发垃圾回收，而这次回收其实不是必要的。

![](Images/js_memo_03.png)

为了解决内存碎片问题，`Mark-Compact` 被提出，它是在是在 `Mark-Sweep` 的基础上演进而来的，相比 `Mark-Sweep`，`Mark-Compact` 添加了活动对象整理阶段，将所有的活动对象往一端移动，移动完成后，直接清理掉边界外的内存。

![](Images/js_memo_09.gif)

###### 全停顿 Stop-The-World

由于垃圾回收是在 `JS` 引擎中进行的，而 `Mark-Compact` 算法在执行过程中需要移动对象，而当活动对象较多的时候，它的执行速度不可能很快，为了避免 `JavaScript` 应用逻辑和垃圾回收器的内存资源竞争导致的不一致性问题，垃圾回收器会将 JavaScript 应用暂停，这个过程，被称为全停顿（stop-the-world）。

在新生代中，由于空间小、存活对象较少、`Scavenge` 算法执行效率较快，所以全停顿的影响并不大。而老生代中就不一样，如果老生代中的活动对象较多，垃圾回收器就会暂停主线程较长的时间，使得页面变得卡顿。

##### 优化 Orinoco

`orinoco` 为 `V8` 的垃圾回收器的项目代号，为了提升用户体验，解决全停顿问题，它利用了**增量标记**、**懒性清理**、**并发**、**并行**来降低主线程挂起的时间。

###### 增量标记 - Incremental marking

为了降低全堆垃圾回收的停顿时间，增量标记将原本的标记全堆对象拆分为一个一个任务，让其穿插在 `JavaScript` 应用逻辑之间执行，它允许堆的标记时的 `5~10ms` 的停顿。增量标记在堆的大小达到一定的阈值时启用，启用之后每当一定量的内存分配后，脚本的执行就会停顿并进行一次增量标记。

![](Images/js_memo_04.png)

###### 懒性清理 - Lazy sweeping

增量标记只是对活动对象和非活动对象进行标记，惰性清理用来真正的清理释放内存。当增量标记完成后，假如当前的可用内存足以让我们快速的执行代码，其实我们是没必要立即清理内存的，可以将清理的过程延迟一下，让 `JavaScript` 逻辑代码先执行，也无需一次性清理完所有非活动对象内存，垃圾回收器会按需逐一进行清理，直到所有的页都清理完毕。

增量标记与惰性清理的出现，使得主线程的最大停顿时间减少了 `80%`，让用户与浏览器交互过程变得流畅了许多，从实现机制上，由于每个小的增量标价之间执行了 `JavaScript` 代码，堆中的对象指针可能发生了变化，需要使用写屏障技术来记录这些引用关系的变化，所以也暴露出来增量标记的缺点：

1. 并没有减少主线程的总暂停的时间，甚至会略微增加
2. 由于写屏障（Write-barrier）机制的成本，增量标记可能会降低应用程序的吞吐量

###### 并发 - Concurrent

并发式 `GC` 允许在在垃圾回收的同时不需要将主线程挂起，两者可以同时进行，只有在个别时候需要短暂停下来让垃圾回收器做一些特殊的操作。但是这种方式也要面对增量回收的问题，就是在垃圾回收过程中，由于 `JavaScript` 代码在执行，堆中的对象的引用关系随时可能会变化，所以也要进行写屏障操作。

![](Images/js_memo_05.png)

###### 并行 - Parallel

并行式 `GC` 允许主线程和辅助线程同时执行同样的 `GC` 工作，这样可以让辅助线程来分担主线程的 `GC` 工作，使得垃圾回收所耗费的时间等于总时间除以参与的线程数量（加上一些同步开销）。

![](Images/js_memo_06.png)

##### V8 当前垃圾回收机制

`2011` 年，`V8` 应用了增量标记机制。直至 `2018` 年，`Chrome64` 和 `Node.js V10` 启动并发标记（Concurrent），同时在并发的基础上添加并行（Parallel）技术，使得垃圾回收时间大幅度缩短。

###### 副垃圾回收器

V8 在新生代垃圾回收中，使用并行（parallel）机制，在整理排序阶段，也就是将活动对象从 `from-to` 复制到 `space-to` 的时候，启用多个辅助线程，并行的进行整理。由于多个线程竞争一个新生代的堆的内存资源，可能出现有某个活动对象被多个线程进行复制操作的问题，为了解决这个问题，`V8` 在第一个线程对活动对象进行复制并且复制完成后，都必须去维护复制这个活动对象后的指针转发地址，以便于其他协助线程可以找到该活动对象后可以判断该活动对象是否已被复制。

![](Images/js_memo_07.png)

###### 主垃圾回收器

V8 在老生代垃圾回收中，如果堆中的内存大小超过某个阈值之后，会启用并发（Concurrent）标记任务。每个辅助线程都会去追踪每个标记到的对象的指针以及对这个对象的引用，而在 `JavaScript` 代码执行时候，并发标记也在后台的辅助进程中进行，当堆中的某个对象指针被 `JavaScript` 代码修改的时候，写入屏障（write barriers）技术会在辅助线程在进行并发标记的时候进行追踪

当并发标记完成或者动态分配的内存到达极限的时候，主线程会执行最终的快速标记步骤，这个时候主线程会挂起，主线程会再一次的扫描根集以确保所有的对象都完成了标记，由于辅助线程已经标记过活动对象，主线程的本次扫描只是进行 `check` 操作，确认完成之后，某些辅助线程会进行清理内存操作，某些辅助进程会进行内存整理操作，由于都是并发的，并不会影响主线程 `JavaScript` 代码的执行。

![](Images/js_memo_08.png)

来源：[深入理解谷歌最强 V8 垃圾回收机制](https://zhuanlan.zhihu.com/p/259579683)

拓展：[Java 和 JavaScript 为什么都需要 VM，由 VM 的 GC 来操作内存？](https://www.zhihu.com/question/449995754)

<!-- [V8引擎的内存管理](https://mp.weixin.qq.com/s/vvZy6rBb8RyTaiBKo5ryHg) -->

### JS 中的內存泄露

尽管 `JS` 为我们自动处理内存的分配、回收问题，但是在某些特定的场景下，`JS` 的垃圾回收算法并不能帮我们去除已经不再使用的内存。这种【由于疏忽或错误造成程序未能释放已经不再使用的内存】的现象，被称作内存泄露。

可能产生内存泄露的场景有不少，包括**全局变量**，`DOM` 事件，定时器等等。

下面是一段存在内存泄露的示例代码：

```jsx
class Page1 extends React.Component {
  events = []

  componentDidMount() {
    window.addEventListener('scroll', this.handleScroll.bind(this))
  }

  render() {
    return (
      <div>
        <div>
          <Link to={'/page2'}>前往Page2</Link>
        </div>
        <p>page1</p>
        ....
      </div>
    )
  }

  handleScroll(e) {
    this.events.push(e)
  }
}
```

当我们点击按钮跳转到 `Page2` 后，在 `page2` 不停进行滚动操作，我们会发现内存占用不断的上涨：

![](Images/js_memo_11.png)

产生这个内存泄露的原因是：我们在 `Page1` 被 `unMount` 的时候，尽管 `Page1` 被销毁了，但是 `Page1` 的滚动回调函数通过 `window.eventListener` 依然可“触达”，所以不会被垃圾回收。

进入 `Page2` 后，滚动事件的逻辑依然生效，内部的变量无法被 `GC`。如果用户在 `Page2` 进行长时间滑动等操作，页面会逐渐变得卡顿。

上述的例子，在我们开发的过程中，并不少见。不仅仅是事件绑定，也有可能是定时上报逻辑等等。如何解决呢？记得在 `unMount` 的时候，进行相应的取消操作即可。

在平时的项目开发中，内存泄露还有很多其他的场景。浏览器页面还好，毕竟一直开着某个页面的用户不算太多，刷新就好。而 `Node.js` 发生内存泄露的后果就比较严重了，可能服务就直接崩溃了。

#### JS 中的弱引用

前面我们讲到了 `JS` 的垃圾回收机制，如果我们持有对一个对象的引用，那么这个对象就不会被垃圾回收。这里的引用，指的是强引用。在计算机程序设计中，还有一个弱引用的概念：一个对象若只被弱引用所引用，则被认为是不可访问（或弱可访问）的，并因此可能在任何时刻被回收。在 `JS` 中，`WeakMap` 和 `WeakSet` 给我们提供了弱引用的能力。

##### WeakMap

`Map` 对象保存键值对，并且能够记住键的原始插入顺序。任何值(对象或者原始值) 都可以作为一个键或一个值。

```js
const m = new Map()
let obj = { a: 1 }
m.set(obj, 'a')
obj = null // 將obj置為null並不會使 { a: 1 } 被垃圾回收，因為還有map引用了 { a: 1 }
```

`WeakMap` 是一组键/值对的集合，其中的键是弱引用的。其键必须是对象，而值可以是任意的。`WeakMap` 是对对象的弱引用

```js
const wm = new WeakMap()
let obj = { b: 2 }
wm.set(obj, '2')
obj = null // 將 obj 置為 null 後，儘管 wm 依然引用了{ b: 2 }，但是由於是弱引用，{ b: 2 } 會在某一時刻被 GC。
```

**正由于这样的弱引用，`WeakMap` 的 `key` 是不可枚举的 (没有方法能给出所有的 `key`)。如果 `key` 是可枚举的话，其列表将会受垃圾回收机制的影响，从而得到不确定的结果。**

`WeakSet` 可以视为 `WeakMap` 中所有值都是布尔值的一个特例，这里就不再赘述了。

> `JavaScript` 的 `WeakMap` 并不是真正意义上的弱引用：实际上，只要键仍然存活，它就强引用其内容。`WeakMap` 仅在键被垃圾回收之后，才弱引用它的内容。这种关系更准确地称为 [ephemeron](https://en.wikipedia.org/wiki/Ephemeron) 。

##### WeakRef

`WeakRef` 是一个更高级的 `API`，它提供了真正的弱引用。我们直接借助上文的内存泄露的例子来看一看 `WeakRef` 的效果：

```jsx
import React from 'react'
import { Link } from 'react-router-dom'

// 使用 WeakRef 將回調函數“包裹”起來，形成對回調函數的弱引用。
function addWeakListener(listener) {
  const weakRef = new WeakRef(listener)
  const wrapper = e => {
    if (weakRef.deref()) {
      return weakRef.deref()(e)
    }
  }
  window.addEventListener('scroll', wrapper)
}

class Page1 extends React.Component {
  events = []

  componentDidMount() {
    addWeakListener(this.handleScroll.bind(this))
  }

  componentWillUnmount() {
    console.log(this.events)
  }

  render() {
    return (
      <div>
        <div>
          <Link to={'/page2'}>前往Page2</Link>
        </div>
        <p>page1</p>
        ....
      </div>
    )
  }

  handleScroll(e) {
    this.events.push(e)
  }
}

export default Page1
```

我们再来看看点击按钮跳转到 `page2` 后的内存表现：

![](Images/js_memo_12.png)

可以很直观的看到，在跳转到 `page2` 后，持续滚动一段时间后，内存平稳。这是因为随着 `page1` 被 `unMount`，真正的滚动回调函数（ `Page1` 的 `handleScroll` 函数）被 `GC` 掉了。其内部的变量也最终被 `GC`。

但其实，这里还有一个问题，虽然我们通过 `weakRef.deref()` 拿不到 `handleScroll` 滚动回调函数了（已被 GC），但是我们的包裹函数 `wrapper` 依然会执行。因为我们没有执行 `removeEventListener`。理想情况是：我们希望滚动监听函数也被取消掉。可以借助 `FinalizationRegistry` 来实现这个功能。看下面的示例代码：

```js
// FinalizationRegistry 構造函數接受一個回調函數作為參數，返回一個示例。我們把實例註冊到某個對象上，當該對象被 GC 時，回調函數會觸發。
const gListenersRegistry = new FinalizationRegistry(({ window, wrapper }) => {
  console.log('GC happen!!')
  window.removeEventListener('scroll', wrapper)
})

function addWeakListener(listener) {
  const weakRef = new WeakRef(listener)
  const wrapper = e => {
    console.log('scroll')
    if (weakRef.deref()) {
      return weakRef.deref()(e)
    }
  }
  // 新增這行代碼，當 listener 被 GC 時，會觸發回調函數。回調函數傳參由我們自己控制。
  gListenersRegistry.register(listener, { window, wrapper })
  window.addEventListener('scroll', wrapper)
}
```

> `WeakRef` 和 `FinalizationRegistry` 属于高级 `Api`，在 `Chrome v84` 和 `Node.js 13.0.0` 后开始支持。一般情况下不建议使用。因为容易用错，导致更多的问题。

#### 关于 JS 闭包是否真的会造成内存泄漏？

内存泄露是指你「用不到」（访问不到）的变量，依然占居着内存空间，不能被再次利用起来。闭包里面的变量就是我们需要的变量，不能说是内存泄露。

跟闭包和内存泄露有关系的地方是，使用闭包的同时比较容易形成循环引用，如果闭包的作用域链中保存着一些 `DOM` 节点，这时候就有可能造成内存泄露。但这本身并非闭包的问题，也并非 `JavaScript` 的问题。

在 `IE` 浏览器中，由于 `BOM` 和 `DOM` 中的对象是使用 `C++` 以 `COM` 对象的方式实现的，而 `COM` 对象的垃圾收集机制采用的是引用计数策略。在基于引用计数策略的垃圾回收机制中，如果两个对象之间形成了循环引用，那么这两个对象都无法被回收，但循环引用造成的内存泄露在本质上也不是闭包造成的。

老浏览器（主要是 `IE6`）由于垃圾回收有问题导致很容易出现内存泄漏。**但是那是浏览器实现的 `bug`**

**循环引用对现代浏览器也不是问题了**

### `Babel` 的编译过程？

### `JavaScript` 中的数组在内存中是如何存储的？

#### 什么是数组

> 数据结构中定义的数组是定长的、数据类型一致的存储结构。

看完数据结构中的定义，再来看下具体语言中对数组的实现：`C、C++、Java、Scala` 等语言中数组的实现，是通过在内存中划分一串连续的、固定长度的空间，来实现存放一组有限个相同数据类型的数据结构。这里面也涉及到了几个重要的概念：**连续**、**固定长度**、**相同数据类型**，与数据结构中的定义是类似的。

1. **连续**

   连续空间存储是数组的特点。各元素在内存中是相邻的，是一种线性的存储结构。

2. **固定长度**

   因为数组的空间是连续的，这就意味着在内存中会有一整块空间来存放数组，如果不是固定长度，那么内存中位于数组之后的区域会没办法分配，内存不知道数组还要不要继续存放，要使用多长的空间。长度固定，就界定了数组使用内存的界限，数组之外的空间可以分配给别人使用。

3. **相同数据类型**

   因为数组的长度是固定的，如果不是相同数据类型，一会存一个 `int` ，一会存一个 `String` ，两种不同长度的数据类型，不能保证各自存放几个，这样有悖固定长度的规定，所以也要是相同的数据类型。

那我们再来看 `JavaScript` 中的数组。

#### JavaScript 中的数组

> `JS` 的数组不是基础的数据结构（数组）实现的，而是在基础上面做了一些封装。

- `JS` 数组中不止可以存放上面的三种数据类型，它可以存放数组、对象、函数、`Number`、`Undefined`、`Null`、`String`、`Boolean` 等等。

- `JS` 的数组可以表现的像栈一样，为数组提供了 `push()`和 `pop()`方法。也可以表现的像队列一样，使用 `shift()`和 `push()`方法，可以像使用队列一样使用数组。

#### 从 V8 源码上看数组的实现

![](Images/array_02.png)

从注释上可以看出，`JS` 数组有两种表现形式，`fast` 和 `slow`

- **fast** ：

快速的后备存储结构是 `FixedArray` ，并且 `数组长度 <= elements.length()`

> `FixedArray` 是 `V8` 实现的一个类似于数组的类，它表示一段固定长度的连续的内存。

- **slow** ：

缓慢的后备存储结构是一个以数字为键的 `HashTable` 。

> `HashTable`，维基百科中解释的很好：

> 散列表（Hash table，也叫哈希表），是根据键（Key）而直接访问在内存存储位置的数据结构。也就是说，它通过计算一个关于键值的函数，将所需查询的数据映射到表中一个位置来访问记录，这加快了查找速度。这个映射函数称做散列函数，存放记录的数组称做散列表。

##### 快数组（Fast Elements）

> TIPS: JS 数组中的数据类型不一样的话，不一定不是快数组

快数组是一种线性的存储方式。

**新创建的空数组，默认的存储方式是快数组，快数组长度是可变的**，可以根据元素的增加和删除来动态调整存储空间大小，内部是通过扩容和收缩机制实现，那来看下源码中是怎么扩容和收缩的。

1. 扩容

```js
new_capacity = old_capacity / 2 + old_capacity + 16
```

也就是，扩容后的新容量 = 旧容量的 `1.5` 倍 + `16`

扩容后会将数组拷贝到新的内存空间中

2. 收缩

收缩数组的判断是：如果`容量 >= length 的 2 倍 + 16`，则进行收缩容量调整，否则用 `holes` 对象（什么事 `holes` 对象？下面来解释）填充未被初始化的位置。

```c
int elements_to_trim = length + 1 == old_length ? (capacity -length) / 2 : capacity -length
```

这个 `elements_to_trim` 就是需要收缩的大小，需要根据 `length + 1` 和 `old_length` 进行判断，是将空出的空间全部收缩掉还是只收缩二分之一

3. `holes`（空洞）对象

`holes`（空洞）对象指的是数组中分配了空间，但是没有存放元素的位置。

对于 `holes`，快数组中有个专门的模式，在 `Fast Elements` 模式中有一个扩展，是 `Fast Holey Elements` 模式。
`Fast Holey Elements` 模式适合于数组中的 `holes`（空洞）情况，即只有某些索引存有数据，而其他的索引都没有赋值的情况。

那什么时候会是 `Fast Holey Elements` 模式呢？

当数组中有空洞，没有赋值的数组索引将会存储一个特殊的值，这样在访问这些位置时就可以得到 `undefined`。这种情况下就会是 `Fast Holey Elements` 模式。
`Fast Holey Elements` 模式与 `Fast Elements` 模式一样，会动态分配连续的存储空间，分配空间的大小由最大的索引值决定。

**新建数组时，如果没有设置容量**，`V8` 会默认使用 `Fast Elements` 模式实现。比如 `let a = new Array(1,2,3);`，这种就不存在空洞，就是以 `Fast Elements` 模式实现

如果要对数组设置容量，但并没有进行内部元素的初始化，例如 `let a = new Array(10);`，这样的话数组内部就存在了空洞，就会以 `Fast Holey Elements` 模式实现。

##### 慢数组（Dictionary Elements）

慢数组是一种哈希表的内存形式。不用开辟大块连续的存储空间，节省了内存，但是由于需要维护这样一个 `HashTable`，其效率会比快数组低。

那既然有快数组和慢数组，总不能存储结构一成不变吧，也该有具体情况下的快慢数组转换，下面来看一下什么情况下会发生转换

##### 快数组慢数组之间的转换

**快 -> 慢**

- `新容量 >= 3 * 扩容后的容量 * 2` ，会转变为慢数组。

- 当加入的 `index- 当前 capacity >= kMaxGap（1024` 时（也就是至少有了 `1024` 个空洞），会转变为慢数组。

也就是说，当对数组赋值时使用远超`当前数组的容量+ 1024` 时（这样出现了大于等于 `1024` 个空洞，这时候要对数组分配大量空间则将可能造成存储空间的浪费，为了空间的优化，会转化为慢数组。

```js
let a = [1, 2]
a[1030] = 1
```

数组中只有三个元素，但是却在 `1030` 的位置存放了一个值，那么中间会有多于 `1024` 个空洞，这时就会变为慢数组

**慢 -> 快**

处于哈希表实现的数组，在每次空间增长时， `V8` 的启发式算法会检查其空间占用量， 若其空洞元素减少到一定程度，则会将其转化为快数组模式。

当慢数组的元素可存放在快数组中且长度在 `smi` 之间且仅节省了 `50%` 的空间,则会转变为快数组

![](Images/array_03.png)

```js
let a = [1, 2]
a[1030] = 1
for (let i = 200; i < 1030; i++) {
  a[i] = i
}
```

在 `1030` 的位置上面添加一个值，会造成多于 `1024` 个空洞，数组会使用为 `Dictionary` 模式来实现。

那么我们现在往这个数组中再添加几个值来填补空洞，往 `200-1029` 这些位置上赋值，使慢数组不再比快数组节省 `50%` 的空间，数组变成了快数组的 `Fast Holey Elements` 模式。

##### 各有优劣

快数组就是以空间换时间的方式，申请了大块连续内存，提高效率。 慢数组以时间换空间，不必申请连续的空间，节省了内存，但需要付出效率变差的代价。

#### 扩展：ArrayBuffer

`JS` 在 `ES6` 也推出了可以按照需要分配连续内存的数组，这就是 `ArrayBuffer`。

`ArrayBuffer` 会从内存中申请设定的二进制大小的空间，但是并不能直接操作它，需要通过 `ArrayBuffer` 构建一个视图，通过视图来操作这个内存。

```js
var bf = new ArrayBuffer(1024)
```

这行代码就申请了 `1kb` 的内存区域。但是并不能对 `arrayBuffer` 直接操作，需要将它赋给一个视图来操作内存。

```js
var b = new Int32Array(bf)
```

这行代码创建了有符号的 `32` 位的整数数组，每个数占 `4` 字节，长度也就是 `1024 / 4 = 256` 个。

来源：[探究 JS V8 引擎下的“数组”底层实现](https://juejin.cn/post/6844903943638794248)

### 浏览器和 `Node` 中的事件循环机制有什么区别？

#### 浏览器

#### Node

### `ES6 Modules` 相对于 `CommonJS` 的优势是什么？

### 什么是沙箱？浏览器的沙箱有什么作用？

### 发布 / 订阅模式和观察者模式的区别是什么？

### 装饰器模式一般会在什么场合使用？

### 什么是函数式编程？什么是响应式编程？什么是函数响应式编程？

## 语法

## 框架

## 工程

## 网络

## 性能

## 插件

## 系统

## 后端

<!-- https://www.bilibili.com/video/BV18M4y1u78g?p=1s -->
