const path = require('node:path');
const fs = require('node:fs');
const express = require('express');
const { promisify } = require('node:util');
const multer = require('multer');

const router = express.Router();
const chunkPathMap = new Map();

const uploadDir = path.resolve(__dirname, 'large');
const storage = multer({ dest: uploadDir });

router.post('/chunk', async (req, res) => {
  const storageAnyPromise = promisify(storage.any());
  try {
    // åŸç”Ÿ formData æ˜¯æµï¼Œéœ€è¦ç›‘å¬ data äº‹ä»¶æ¥æ¥æ”¶æ•°æ®å—ï¼Œä¹‹åè§£æã€‚æ‰€ä»¥ä½¿ç”¨ multer æ¥å¤„ç†
    // è¿™ä¸€æ­¥ä¼šå¾€ req, res ä¸­æ³¨å…¥æ–‡ä»¶ä¿¡æ¯
    await storageAnyPromise(req, res);

    // éæ–‡ä»¶æ•°æ®åœ¨ req.body ä¸­
    console.log('ğŸš€ ~ req.body:', req.body);
    // æ–‡ä»¶æ•°æ®åœ¨ req.files ä¸­
    console.log('ğŸš€ ~ req.files:', req.files);

    const chunkIndex = req.body.index;
    const fileHash = req.body.fileHash;
    const newFilePath = path.join(uploadDir, `${fileHash}-${chunkIndex}`);

    // ä½¿ç”¨ fileHash + ä¸‹æ ‡ä½œä¸ºåˆ‡ç‰‡åé‡å‘½åä¸Šä¼ çš„æ–‡ä»¶
    fs.renameSync(req.files[0].path, newFilePath);
    // å°†åˆ‡ç‰‡è·¯å¾„ä¿å­˜åˆ° map ä¸­ï¼Œåç»­åˆå¹¶æ—¶ä½¿ç”¨
    chunkPathMap.set(chunkIndex, newFilePath);

    res.json({
      message: 'ä¸Šä¼ æˆåŠŸ',
    });
  } catch (error) {
    console.log('ğŸš€ ~ err:', err);
  }
});

router.post('/merge', async (req, res) => {
  if (!chunkPathMap.size) {
    return res.status(400).json({ message: 'æ²¡æœ‰æ–‡ä»¶åˆ‡ç‰‡' });
  }
  const { fileName, fileHash, size } = req.body;
  const extension = fileName.split('.').pop();
  const filePath = path.resolve(uploadDir, `${fileHash}.${extension}`);

  // å†™å…¥æ–‡ä»¶æµ
  const pipeStream = (chunkPath, writeStream) =>
    new Promise((resolve) => {
      const readStream = fs.createReadStream(chunkPath);
      readStream.on('end', () => {
        fs.unlinkSync(chunkPath);
        resolve();
      });
      readStream.pipe(writeStream);
    });

  try {
    // å¹¶å‘å†™å…¥æ–‡ä»¶
    await Promise.all(
      Array.from(chunkPathMap)
        .sort((a, b) => {
          return a[0] - b[0];
        })
        .map(([index, chunkPath]) => pipeStream(chunkPath, fs.createWriteStream(filePath, { start: index * size }))),
    );
    // æ¸…ç©º chunkPathMap
    chunkPathMap.clear();
    res.json({ message: 'æ–‡ä»¶åˆå¹¶æˆåŠŸ' });
  } catch (err) {
    console.log(err);
    res.status(500).json({ message: 'åˆå¹¶æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯', error: err });
  }
});

// åœ¨ä¸Šä¼ å‰ï¼Œå…ˆè®¡ç®—å‡ºæ–‡ä»¶ hashï¼Œå¹¶æŠŠ hash å‘é€ç»™æœåŠ¡ç«¯è¿›è¡ŒéªŒè¯ï¼Œç”±äº hash çš„å”¯ä¸€æ€§ï¼Œæ‰€ä»¥ä¸€æ—¦æœåŠ¡ç«¯èƒ½æ‰¾åˆ° hash ç›¸åŒçš„æ–‡ä»¶ï¼Œåˆ™ç›´æ¥è¿”å›ä¸Šä¼ æˆåŠŸçš„ä¿¡æ¯å³å¯
router.post('/verify', async (req, res) => {
  const { fileName, fileHash } = req.body;
  const extension = fileName.split('.').pop();
  const filePath = path.resolve(uploadDir, `${fileHash}.${extension}`);
  // æœåŠ¡ç«¯å·²å­˜åœ¨è¯¥æ–‡ä»¶ï¼Œä¸éœ€è¦å†æ¬¡ä¸Šä¼ 
  if (fs.existsSync(filePath)) {
    res.json({
      message: 'æœåŠ¡ç«¯å·²å­˜åœ¨è¯¥æ–‡ä»¶ï¼Œä¸éœ€è¦å†æ¬¡ä¸Šä¼ ',
      shouldUpload: false,
    });
  } else {
    // æœåŠ¡ç«¯ä¸å­˜åœ¨è¯¥æ–‡ä»¶æˆ–è€…å·²ä¸Šä¼ éƒ¨åˆ†æ–‡ä»¶åˆ‡ç‰‡ï¼Œé€šçŸ¥å‰ç«¯è¿›è¡Œä¸Šä¼ ï¼Œå¹¶æŠŠå·²ä¸Šä¼ çš„æ–‡ä»¶åˆ‡ç‰‡è¿”å›ç»™å‰ç«¯
    // å…¶ä»–æœªå®Œå…¨å®Œæˆçš„ä¸Šä¼ ç¢ç‰‡åº”è¯¥åˆ é™¤
    const files = fs.readdirSync(uploadDir);
    files.forEach((file) => {
      // æ–‡ä»¶åæ ¼å¼ä¸º hash-indexï¼Œæ‰€ä»¥åªè¦ hash ç›¸åŒï¼Œåˆ™è¯´æ˜æ˜¯åŒä¸€ä¸ªæ–‡ä»¶çš„åˆ‡ç‰‡
      // ç¢ç‰‡æ–‡ä»¶åæ˜¯ multer è‡ªå®šä¹‰çš„ï¼Œç¢ç‰‡æ–‡ä»¶ä¸Šä¼ æˆåŠŸåä¼šé‡å‘½åã€‚36 æ˜¯ä¸ªé­”æ³•å€¼ï¼Œä»¥åæ›´æ”¹ã€‚
      if (file.length < 36) {
        fs.unlinkSync(path.resolve(uploadDir, file));
      }
    });

    if (files.length > 0) {
      return res.json({
        message: 'å·²ä¸Šä¼ éƒ¨åˆ†æ–‡ä»¶åˆ‡ç‰‡',
        uploadedChunks: files.filter((file) => file.includes(fileHash)),
        shouldUpload: true,
      });
    }

    res.json({
      message: 'æœåŠ¡ç«¯ä¸å­˜åœ¨è¯¥æ–‡ä»¶',
      shouldUpload: true,
    });
  }
});

module.exports = router;
