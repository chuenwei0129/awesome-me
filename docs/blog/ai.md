跟ChatGPT交互，最重要是掌握Prompt的模板或者说结构，而不需要记住那么多Prompt。

一、基础用法
直接输入你希望的指令，例如：

“请将以下内容翻译为简体中文：”
“请生成以下内容的摘要：”
“请给10岁的孩子解释什么是ChatGPT”

基本上一大半的需求就直接可以满足，如果想效果更好一点，可以为GPT指定一个角色，这样效果会稍微好一点。例如：
“你是一位专业的英文翻译，请翻译以下内容为简体中文：”

附：为什么要指定角色

提供一到多个示例，通过示例来让GPT按照你期望的格式输出，比如这个例子：

------
你是一个专业翻译，擅长翻译英文到中文，但是注意双引号内的英文不翻译。
例如：
"Dichroic-Filter" - Separates light into different wavelengths to create a color separation
effect.
翻译为：
"Dichroic-Filter"- 将光分离成不同的波长以创建颜色分离效果。

请翻译以下内容：
------

结合示例，基本上大部分问题都可以解决。

三、高级

链式思考（分多步做）+ 慢思考（打印每一步的结果）

对于一些复杂的推理过程，如果直接让GPT给出答案，是很容易出错的！最好是让GPT一步步来做，并且打印出中间步骤。在OpenAI官方文档里面，有一篇《GPT最佳实践》https://platform.openai.com/docs/guides/gpt-best-practices/tactic-instruct-the-model-to-work-out-its-own-solution-before-rushing-to-a-conclusion ，就举了一个很好的例子来给学生做助教，在收到学生的问题后，不直接给出正确或者错误的结果，而是：

------
按照这些步骤来回答用户的询问。

第1步--首先找出你自己的问题解决方案。不要依赖学生的解决方案，因为它可能是不正确的。在这一步中，你的所有工作都要用三重引号(""")括起来。

第2步--将你的解决方案与学生的解决方案进行比较，评估学生的解决方案是否正确。将你在这一步的所有工作都放在三重引号(""")内。

第3步--如果学生犯了错误，确定你可以在不泄露答案的情况下给学生什么提示。把你在这一步的所有工作都放在三重引号(""")内。

第4步--如果学生犯了一个错误，向学生提供上一步的提示（在三重引号之外）。不要写 "第4步--..."，而是写 "提示："。
------

当然你还可以在链式思考这个基础上加上几个示例，效果更佳。

最后，下面是一个模板，绝大部分场景都可以直接套用模板而不需要记住所谓GPT最权威的160条指令，这些指令都不会超出下面的范围。

✅ 角色、技能、个性
✅ 目标
✅ 具体的上下文、关键词、负面词
✅ 输入规则
✅ 输出规则
✅ 输入输出的例子

熟悉Prompt的同学们应该都知道，通常在写Prompt的时候要先设定角色：“你是XX方面的专家”，这并非玄学，而是有科学根据的。

GPT在训练的时候，有各种训练数据，有的质量高有的质量低，而默认情况下，生成高质量数据和低质量数据的概率差不多，但是当你给它设定XX专家的角色时，它会尽可能把概率分布在高质量的解决方案上。

OpenAI 终于开放了 GPT-3.5 的微调的API，如果嫌开源模型不够好用，又舍得花钱的话，真的是个好的选择。

花了点时间研究了一下官方的文档和Cookie Book，帮大家总结一下微调的一些常见问题。

1. 什么是微调（Fine-tuning）？

通常我们说的微调，指的是基于已经训练好的语言模型，使用小规模的特定的数据集继续训练它，让它更适应于特定的任务或领域。

这不太好理解，没关系继续看，第二个问题通过打比方可以帮助你更容易的理解。

2. 微调和提示工程（Prompt Engineering）、嵌入（Embedding）、智能体（Agent）区别是什么？

这几个概念有相同的地方，也有差别，让我通过两个比喻来解释。

第一个经典比喻来自王建硕老师，他把LLM（大语言模型）比喻为一个已经训练好的家政阿姨，她懂中文，会做家务，但是对你家里的情况不了解。

微调：就相当于阿姨第一次到你家干活的时候，你要花一小时时间告诉她家里的情况，比如物件的摆放、哪些地方不能动，哪些地方要重点照顾。

嵌入：就相当于你省去了对阿姨进行二次培训的，而是在家里贴满纸条，这样阿姨需要做什么事先找纸条，一看到纸条就知道该怎么做了。

基于他的比喻我延伸一下：

提示工程：就是你给阿姨的指令，告诉阿姨应该做什么事情，同时为了让阿姨能圆满完成任务，在指令里通常需要包含很多背景信息。然后阿姨借助她自己的语言能力和推理能力，理解你的指令，做出推理，最终给出回应。另外阿姨记性不太好，你一次不能说太长的内容（上下文窗口长度限制）

智能体：就好比让阿姨去修家里坏了的电视，阿姨不会修，但是阿姨知道该找修电视的，于是阿姨把修电视的叫过来把电视修了，那这个修电视的就是智能体，能帮助大语言模型处理它能力之外的事。

另一个比喻是如果把LLM比作大学生：

提示工程：就好比考试的问题，问题中提供了一定的背景知识和要求，然后学生按照问题的要求和背景知识，进行推理，最终给出答案。限于考卷的长度，你的问题和学生的答案都不能太长（上下文窗口长度限制）

微调：就好比大学生要突击某门考试，考试前给这个学生一些这门课的指定格式的问题和答案，让学生记住这些知识，并且考试的时候按照上面的格式回复。

嵌入：就像记笔记，是一种短期记忆，当考试的时候，你把笔记带上，遇到问题先翻看笔记，对于笔记上有的内容可以得到准确的答案，另外由于上下文窗口长度的限制，你每次只能抄笔记本上几段的内容。

智能体：就好比考数学，学生可以带高级计算器，遇到不会算的问题，学生直接用计算器就可以得到答案，计算器就相当于智能体。

要编写优质的prompt，从日常实践来看，用下述结构，并且提出非常具体的要求，则基本可以让LLM输出你想要的结果

✅ 角色、技能、个性
✅ 目标
✅ 具体的上下文、关键词、负面词
✅ 输入规则
✅ 输出规则
✅ 输入输出的例子

附图是两个优秀的Prompt：AutoGPT核心指令+小红书写手。都覆盖了框架的大部分 



https://lobehub.com/zh/docs/usage/agents/model

核心原理:语言模型：在一个问答框架下，基于一个单词，预测下一个单词

基于互联网大量知识训练，掌握的知识越多，单词预测概率越准确

<!-- MARK: 核心原理 -->

:::info
This is an info box.
:::

:::info{title=自定义标题}
这是一条普通信息
:::

:::danger STOP
Danger zone, do not proceed
:::

:::details Click me to view the code
# ```js
console.log('Hello, VitePress!')
# ```
:::

```jsx
import React from 'react';

export default () => {
  return (<svg width="100" height="200" viewBox="0 0 100 200" xmlns="http://www.w3.org/2000/svg">
  <rect x="40" y="60" width="20" height="80" fill="#555555" />
  <polygon points="50,30 35,60 65,60" fill="#777777" />
  <polygon points="40,140 20,160 40,160" fill="#777777" />
  <polygon points="60,140 80,160 60,160" fill="#777777" />
  <polygon points="50,140 30,180 50,160 70,180" fill="#FF4500" />
  <polygon points="50,160 40,190 50,180 60,190" fill="#FFA500" />
</svg>)
}
```

借助ChatGPT写小说这事比较难：
1. 怎么让它按照你的想法来写？
2. 怎么保证情节的连贯性
3. 上下文长度有限制

我们先从简单一点的开始：如何在上下文长度限制范围内，写一短篇小说，这样就没必要去摘要和外部存储了。

那么我们需要重点考虑的就是如何能让GPT按照自己的想法来写作，甚至于超越自己写出更好的内容？

如果关注过以前的 #Prompt思考题 ，我经常提到的一个Prompt技巧是CoT，也就是让ChatGPT能把复杂的事情拆分成一步步来做，形成一个思考链，这样生成的质量会比较高。

写作这事也是类似的，要最大化ChatGPT写作的效果，我们需要把写小说这个复杂的任务拆分成一步步的、简单的子任务。

想象一下一个真正的作家是怎么写小说的：
- 他们应该有一个整体的构想；
- 然后基于这个构思写一个大纲，包括人物列表和每个人物的简短描述；
- 再根据大纲生成章节列表和每章内容的简短概述。
（我不是专业作家，有错的话还请指正）

我们也可以按照这个思路，首先把自己小说的构想，甚至可以没有啥想法只是一个标题，告诉GPT，让GPT帮生成一个大纲，包括人物列表和每个人物的简短描述，包括章节列表和每章内容的简短概述。
