---
group:
  title: 2024 🐲
  order: -2024
title: 关于 AI 的思考
toc: content
---

## 如何写好 Prompt

> TODO

## AI 辅助编程

> TODO

## 如何处理大量数据与 ChatGPT 互动

在使用 ChatGPT（或其他类似的大语言模型）时，直接通过对话框输入输出大量数据（如一本书）是不可行的。这是由于输入内容有上下文窗口限制。具体来说，例如 ChatGPT 的 GPT-4 模型，最多能处理 32K 字符的上下文窗口，这相当于大约 50 页的英文文本，而中文文本则更少。这意味着你无法一次性输入完整的《三国演义》或《红楼梦》。那么，有几种方法可以绕过这个限制：

### 1. 预训练阶段直接包含内容 📚

在大语言模型的预训练阶段，内容如《红楼梦》或《三国演义》可能已经被包括在内。这种情况下，当你提问时，不需要完整地传入这些内容，但有时会出现幻觉现象，或者模型生成的回答不够准确。如当你要求它默写《三国演义》的某一特定章节时，未必能完全正确。

### 2. 微调模型 🛠️

对于特定内容，可以通过微调的方式，让模型学习新的知识和文本风格。为了实现这一点，需要先将内容分成多个小块，每块只包含几页内容，并且这些内容要被制作为成对的问题和答案。然而，即便进行了微调，模型学到的知识未必是完整的。此外，微调还涉及高昂的成本，且提问的问题若与微调时不同，生成效果可能不理想。

### 3. 使用 RAG（检索增强生成） 🔍

RAG 方法是当前的主流方案。它不需要在预训练阶段就提供长文本内容，而是根据用户提问动态检索相关段落，再将提问与检索结果一起交给 ChatGPT 处理。这种方法基于用户的问题提取关键词，并在长文本中找出最相关的段落，以辅助回答。

例如：如果你问 ChatGPT “三顾茅庐是哪三顾？”模型会提取出 “三顾茅庐” 的关键词，然后在文档中检索相关章节，将这些段落提供给 ChatGPT。最终，模型会根据这些段落和你的问题生成一个综合的回答。这样一来，无需一次性传入整本书。

检索最相关内容是一项复杂的任务，需要有效的算法来确保高效和精准的检索以支撑模型生成准确回答。

---

通过上述三种方法，可以克服原有输入输出限制，优化与大语言模型的互动体验，以便在包含大量数据的情况下获得理想的回答。
